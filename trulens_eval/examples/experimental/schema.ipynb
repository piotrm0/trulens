{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90737af0-2a1b-47cc-8068-299703ce14be",
   "metadata": {},
   "source": [
    "## Experimenting with Typescript def generation\n",
    "\n",
    "**Status**\n",
    "1. Bumping into issues getting correct schema for properties defined by Span.attribute_property(), likely because they are not initialized at the start.\n",
    "2. Otherwise, this notebook should provide a scaffolding for generating typescript types.\n",
    "3. The types generated is quite repetitive - the schema doesn't understand models extending each other haha.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3120fefe-72c5-46e0-b2e3-1e96ae39eede",
   "metadata": {},
   "source": [
    "To get this working, install https://www.npmjs.com/package/json-schema-to-typescript using `npm i -g json-schema-to-typescript` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59383412-ee9d-41fb-a0cc-3ec41689672f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "PATH_TO_TRULENS=\"../../../../trulens\"\n",
    "sys.path.append(PATH_TO_TRULENS + \"/trulens_eval\")\n",
    "\n",
    "import json\n",
    "\n",
    "import opentelemetry.trace.span as ot_span\n",
    "import opentelemetry.trace as ot_trace\n",
    "\n",
    "from trulens_eval.trace import OTSpan\n",
    "from trulens_eval.trace import WithHashableSpanContext\n",
    "from trulens_eval.trace.span import Span\n",
    "from trulens_eval.trace.span import SpanAgent\n",
    "from trulens_eval.trace.span import SpanEmbedding\n",
    "from trulens_eval.trace.span import SpanLLM\n",
    "from trulens_eval.trace.span import SpanMemory\n",
    "from trulens_eval.trace.span import SpanMethodCall\n",
    "from trulens_eval.trace.span import SpanOther\n",
    "from trulens_eval.trace.span import SpanReranker\n",
    "from trulens_eval.trace.span import SpanRetriever\n",
    "from trulens_eval.trace.span import SpanRoot\n",
    "from trulens_eval.trace.span import SpanTask\n",
    "from trulens_eval.trace.span import SpanTool\n",
    "from trulens_eval.trace.span import SpanType\n",
    "from trulens_eval.trace.span import SpanTyped\n",
    "from trulens_eval.trace.span import SpanUntyped\n",
    "from trulens_eval.trace.span import TransSpanRecord\n",
    "from trulens_eval.trace.span import TransSpanRecordAppCall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9a92f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install -U pydantic opentelemetry-api opentelemetry-sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcda017",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import TypeAdapter\n",
    "TypeAdapter(ot_span.SpanContext).core_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3a8c08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410c024f-5a04-4186-bdac-1c36ee3c2f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://github.com/phillipdupuis/pydantic-to-typescript/tree/master\n",
    "\n",
    "import argparse\n",
    "import importlib\n",
    "import inspect\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "from importlib.util import module_from_spec, spec_from_file_location\n",
    "from tempfile import mkdtemp\n",
    "from types import ModuleType\n",
    "from typing import Any, Dict, List, Tuple, Type\n",
    "from uuid import uuid4\n",
    "\n",
    "from pydantic import BaseModel, Extra, create_model\n",
    "\n",
    "try:\n",
    "    from pydantic.generics import GenericModel\n",
    "except ImportError:\n",
    "    GenericModel = None\n",
    "\n",
    "logger = logging.getLogger(\"pydantic2ts\")\n",
    "\n",
    "\n",
    "def import_module(path: str) -> ModuleType:\n",
    "    \"\"\"\n",
    "    Helper which allows modules to be specified by either dotted path notation or by filepath.\n",
    "\n",
    "    If we import by filepath, we must also assign a name to it and add it to sys.modules BEFORE\n",
    "    calling 'spec.loader.exec_module' because there is code in pydantic which requires that the\n",
    "    definition exist in sys.modules under that name.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if os.path.exists(path):\n",
    "            name = uuid4().hex\n",
    "            spec = spec_from_file_location(name, path, submodule_search_locations=[])\n",
    "            module = module_from_spec(spec)\n",
    "            sys.modules[name] = module\n",
    "            spec.loader.exec_module(module)\n",
    "            return module\n",
    "        else:\n",
    "            return importlib.import_module(path)\n",
    "    except Exception as e:\n",
    "        logger.error(\n",
    "            \"The --module argument must be a module path separated by dots or a valid filepath\"\n",
    "        )\n",
    "        raise e\n",
    "\n",
    "\n",
    "def is_submodule(obj, module_name: str) -> bool:\n",
    "    \"\"\"\n",
    "    Return true if an object is a submodule\n",
    "    \"\"\"\n",
    "    return inspect.ismodule(obj) and getattr(obj, \"__name__\", \"\").startswith(\n",
    "        f\"{module_name}.\"\n",
    "    )\n",
    "\n",
    "\n",
    "def is_concrete_pydantic_model(obj) -> bool:\n",
    "    \"\"\"\n",
    "    Return true if an object is a concrete subclass of pydantic's BaseModel.\n",
    "    'concrete' meaning that it's not a GenericModel.\n",
    "    \"\"\"\n",
    "    if not inspect.isclass(obj):\n",
    "        return False\n",
    "    elif obj is BaseModel:\n",
    "        return False\n",
    "    elif GenericModel and issubclass(obj, GenericModel):\n",
    "        return not inspect.isabstract(obj) # NOTE: This line was changed to make use of the isabstract function rather than checking for the obsolete __concrete__ attribute\n",
    "    else:\n",
    "        return issubclass(obj, BaseModel)\n",
    "\n",
    "\n",
    "def extract_pydantic_models(module: ModuleType) -> List[Type[BaseModel]]:\n",
    "    \"\"\"\n",
    "    Given a module, return a list of the pydantic models contained within it.\n",
    "    \"\"\"\n",
    "    models = []\n",
    "    module_name = module.__name__\n",
    "\n",
    "    for _, model in inspect.getmembers(module, is_concrete_pydantic_model):\n",
    "        models.append(model)\n",
    "\n",
    "    for _, submodule in inspect.getmembers(\n",
    "        module, lambda obj: is_submodule(obj, module_name)\n",
    "    ):\n",
    "        models.extend(extract_pydantic_models(submodule))\n",
    "\n",
    "    return models\n",
    "    \n",
    "def clean_schema(schema: Dict[str, Any]) -> None:\n",
    "    \"\"\"\n",
    "    Clean up the resulting JSON schemas by:\n",
    "\n",
    "    1) Removing titles from JSON schema properties.\n",
    "       If we don't do this, each property will have its own interface in the\n",
    "       resulting typescript file (which is a LOT of unnecessary noise).\n",
    "    2) Getting rid of the useless \"An enumeration.\" description applied to Enums\n",
    "       which don't have a docstring.\n",
    "    \"\"\"\n",
    "    for prop in schema.get(\"properties\", {}).values():\n",
    "        prop.pop(\"title\", None)\n",
    "\n",
    "    if \"enum\" in schema and schema.get(\"description\") == \"An enumeration.\":\n",
    "        del schema[\"description\"]\n",
    "\n",
    "\n",
    "def generate_json_schema(models: List[Type[BaseModel]]) -> str:\n",
    "    \"\"\"\n",
    "    Create a top-level '_Master_' model with references to each of the actual models.\n",
    "    Generate the schema for this model, which will include the schemas for all the\n",
    "    nested models. Then clean up the schema.\n",
    "\n",
    "    One weird thing we do is we temporarily override the 'extra' setting in models,\n",
    "    changing it to 'forbid' UNLESS it was explicitly set to 'allow'. This prevents\n",
    "    '[k: string]: any' from being added to every interface. This change is reverted\n",
    "    once the schema has been generated.\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: replace master model approach with definitions schema\n",
    "    # https://docs.pydantic.dev/latest/api/pydantic_core_schema/#pydantic_core.core_schema.definitions_schema\n",
    "    master_model = create_model(\n",
    "        \"_Master_\", **{m.__name__: (m, ...) for m in models}\n",
    "    )\n",
    "\n",
    "    schema = master_model.model_json_schema(mode='serialization')\n",
    "\n",
    "    for d in schema.get(\"$defs\", {}).values():\n",
    "        clean_schema(d)\n",
    "\n",
    "    return schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139866c9-6e54-485a-b5cd-054bf72c08d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "module = import_module(\"trulens_eval.trace.span\")\n",
    "models = extract_pydantic_models(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae02f1e6-b87b-4d71-b080-b2458285aa4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{PATH_TO_TRULENS}/trulens_eval/trulens_eval/react_components/record_viewer/src/schema/schema.json', 'w+') as f:\n",
    "    json.dump(generate_json_schema(models), f, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c412dc2-436b-427e-91f8-1eb4595957a0",
   "metadata": {},
   "source": [
    "Now, you can run `json2ts -i <path to schema> -o <output_path>`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1b82d6",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
